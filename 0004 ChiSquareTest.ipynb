{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pearson's chi-squared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create contingency table with floats to avoid datatype issues with pd.DataFrame.at \n",
    "ar=np.array([[12.0, 12.0],[11.0, 32.0]])    \n",
    "df=pd.DataFrame(ar, columns=[\"Disease\", \"No Disease\"])\n",
    "df.index=[\"Exposed\", \"Unexposed\"] \n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.copy() # create contingency table with the marginal totals and the grand total. \n",
    "df2.loc['Column_Total']= df2.sum(numeric_only=True, axis=0)\n",
    "df2.loc[:,'Row_Total'] = df2.sum(numeric_only=True, axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=df2.at[\"Column_Total\", \"Row_Total\"]  # grand total \n",
    "\n",
    "exp=df2.copy()               # create dataframe with expected counts\n",
    "for x in exp.index[0:-1]:\n",
    "    for y in exp.columns[0:-1]:\n",
    "        # round expected values to 6 decimal places to get the maximum available precision:\n",
    "        v= (((df2.at[x, \"Row_Total\"]) * (df2.at[\"Column_Total\", y])   )   /n ).round(6) \n",
    "        exp.at[x,y]=float(v)\n",
    "\n",
    "exp = exp.iloc[[0, 1], [0, 1]]\n",
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstat = np.sum(((df-exp)**2/exp).values) # calculate chi-squared test statistic\n",
    "tstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dof = (len(df.columns)-1)*(len(df.index)-1) # determine degrees of freedom \n",
    "dof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval=1-chi2.cdf(tstat, dof) # subtract the cumulative distribution function from 1\n",
    "pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency # import Scipy's built-in function\n",
    "\n",
    "tstat_scipy,pval_scipy,ddof_scipy,exp_scipy=chi2_contingency(df, correction=False) # \"correction=False\" means no Yates' correction is used! \n",
    "print(\"Chi-squared test statistic without Yates correction (Scipy): \" + str(tstat_scipy))\n",
    "print(\"P-value without Yates correction (Scipy): \" + str(pval_scipy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi-squared test with Yates correction:\n",
    "\n",
    "In statistics, Yates's correction for continuity (or Yates's chi-squared test) is used in certain situations when testing for independence in a contingency table. It aims at correcting the error introduced by assuming that the discrete probabilities of frequencies in the table can be approximated by a continuous distribution (chi-squared). In some cases, Yates's correction may adjust too far, and so its current use is limited. \n",
    "\n",
    "All the aforementioned steps are basically the same but we use the following (adjusted) formula to determine our test statistic:\n",
    "\n",
    "$$ \\chi_{Yates}^{2}=  \\sum_{i} \\frac{  \\big(  \\big|O_i-E_i\\big|-0.5  \\big)^{2} }{E_i}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dof = (len(df.columns)-1)*(len(df.index)-1)\n",
    "dof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Yates' correction by subtracting 0.5 from the absolute difference between observed and expected counts: \n",
    "tstat_yates= np.sum((((np.abs(df-exp)-0.5)**2)  / (exp)).values)\n",
    "print(\"Chi-squared test statistic with Yates correction: \" + str(tstat_yates))\n",
    "\n",
    "pval=1-   chi2.cdf(tstat_yates, dof)\n",
    "print(\"P-value with Yates correction: \" + str(pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "tstat_scipy,pval_scipy,ddof_scipy,exp_scipy=chi2_contingency(df, correction=True)# \"correction=True\" to apply Yates' correction\n",
    "print(\"Chi-squared test statistic with Yates correction (Scipy): \" + str(tstat_scipy))\n",
    "print(\"P-value with Yates correction (Scipy): \" + str(pval_scipy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Fisher's exact test)\n",
    "Out of curiosity, Fisher's exact test would give us the following p-value: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "oddsratio, pvalue_fisher = stats.fisher_exact(df)   \n",
    "pvalue_fisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create contingency table with floats to avoid datatype issues with pd.DataFrame.at \n",
    "ar=np.array([[209.0, 280.0],[225.0, 248.0]])    \n",
    "df1=pd.DataFrame(ar, columns=[\"Beach\", \"Cruise\"])\n",
    "df1.index=[\"Men\", \"Women\"] \n",
    "df1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create contingency table with floats to avoid datatype issues with pd.DataFrame.at \n",
    "ar=np.array([[207.0, 282.0],[231.0, 242.0]])    \n",
    "df2=pd.DataFrame(ar, columns=[\"Cat\", \"Dog\"])\n",
    "df2.index=[\"Men\", \"Women\"] \n",
    "df2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement throw pairs example test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for Larry Bird pairs of free throws (basketball I suppose)\n",
    "ar=np.array([[5.0, 82.0, 251.0]])    \n",
    "df3=pd.DataFrame(ar, columns=[0,1,2])\n",
    "df3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
